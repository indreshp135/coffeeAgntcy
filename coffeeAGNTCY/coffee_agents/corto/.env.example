PYTHONPATH=.

#============================
# LLM Provider Settings
#============================
# CoffeeAGNTCY uses litellm to manage LLM connections. 
# Full list of supported providers:c
# Note: In CoffeeAGNTCY, the environment variable for specifying the model is always LLM_MODEL, regardless of the provider.
# Examples:

# OpenAI
# LLM_MODEL="openai/<model_of_choice>"
# OPENAI_API_KEY=<your_openai_api_key>

# Azure OpenAI
# LLM_MODEL="azure/<your_deployment_name>"
# AZURE_API_BASE=https://your-azure-resource.openai.azure.com/
# AZURE_API_KEY=<your_azure_api_key>
# AZURE_API_VERSION=<your_azure_api_version>

# GROQ
# LLM_MODEL="groq/<model_of_choice>"
# GROQ_API_KEY=<your_groq_api_key>

# Google Gemini (recommended)
LLM_MODEL=gemini-2.5-flash-lite
# Single key:
GOOGLE_API_KEY=<your_google_api_key>
# Key rotation (comma-separated): used in round-robin to spread load / rate limits
# GOOGLE_API_KEYS=key1,key2,key3

# NVIDIA NIM
# LLM_MODEL="nvidia_nim/<model_of_choice>"
# NVIDIA_NIM_API_KEY=<your_nvidia_api_key>
# NVIDIA_NIM_API_BASE=<your_nvidia_nim_endpoint_url>

# Recommended temperature setting for OpenAI models
OPENAI_TEMPERATURE=0.7

#============================
# Local Development Settings
#============================
#(not needed when running agents via Docker Compose)

# OTEL environment variables
# OTLP_HTTP_ENDPOINT="http://localhost:4318"

# === Transport Settings ===
# SLIM (Default):
# DEFAULT_MESSAGE_TRANSPORT=SLIM
# TRANSPORT_SERVER_ENDPOINT=http://localhost:46357

# Alternative: NATS transport (uncomment to use NATS). The endpoint address must be in the form: nats://host:port.
# DEFAULT_MESSAGE_TRANSPORT=NATS
# TRANSPORT_SERVER_ENDPOINT=nats://localhost:4222

# === Multi-Agent (Resume / Job Description / Interview Mastermind) ===
# Resume Mastermind (A2A direct HTTP)
# RESUME_MASTERMIND_HOST=localhost
# RESUME_MASTERMIND_PORT=9991

# Job Description Mastermind
# JOB_DESCRIPTION_MASTERMIND_HOST=localhost
# JOB_DESCRIPTION_MASTERMIND_PORT=9992

# Interview Mastermind
# INTERVIEW_MASTERMIND_HOST=localhost
# INTERVIEW_MASTERMIND_PORT=9993
